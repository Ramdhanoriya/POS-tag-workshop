{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.0em;\n",
       "line-height:1.6em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: -0.2em;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "padding-left:1em;\n",
       "padding-right:3em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 2.0em;\n",
    "line-height:1.6em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: -0.2em;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "padding-left:1em;\n",
    "padding-right:3em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">  Generate Parts of Speech tags using various python libraries </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2.1 Generating POS tags using Polyglot library\n",
    "\n",
    "2.2 Generating POS tags using Stanford CoreNLP \n",
    "\n",
    "2.3 Generating POS tags using Spacy library\n",
    "\n",
    "2.4 Why do we need to develop our own POS tagger?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Polyglot library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "2.1.1 Download polyglot POS model for English language\n",
    "\n",
    "2.1.2 Load POS model\n",
    "\n",
    "2.1.3 Import dependencies\n",
    "\n",
    "2.1.4 Detect the language\n",
    "\n",
    "2.1.5 Tokenization of the sentences\n",
    "\n",
    "2.1.6 Generate POS tags for given sentence\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Download polyglot POS model for English language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Slovene                    2. French                     3. Hungarian                \n",
      "  4. Swedish                    5. Spanish; Castilian         6. Portuguese               \n",
      "  7. Indonesian                 8. English                    9. German                   \n",
      " 10. Danish                    11. Czech                     12. Bulgarian                \n",
      " 13. Italian                   14. Irish                     15. Dutch                    \n",
      " 16. Finnish                  \n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(downloader.supported_languages_table(\"pos2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Load POS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/jalaj/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /home/jalaj/polyglot_data...\n",
      "[polyglot_data]   Package pos2.en is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.download(\"embeddings2.en\")\n",
    "downloader.download(\"pos2.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detected: Code=fr, Name=French\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Bonjour, Mesdames.\")\n",
    "print(\"Language Detected: Code={}, Name={}\\n\".format(text.language.code, text.language.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Tokenization of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.']\n"
     ]
    }
   ],
   "source": [
    "words_list = Text(\"Beautiful is better than ugly. \"\n",
    "           \"Explicit is better than implicit. \"\n",
    "           \"Simple is better than complex.\")\n",
    "print(words_list.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Generate POS tags for given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\"We will meet at eight o'clock on Thursday morning.\"\"\"\n",
    "text = Text(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRON'),\n",
       " ('will', 'AUX'),\n",
       " ('meet', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('eight', 'NUM'),\n",
       " (\"o'clock\", 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('Thursday', 'PROPN'),\n",
       " ('morning', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "We              PRON\n",
      "will            AUX\n",
      "meet            VERB\n",
      "at              ADP\n",
      "eight           NUM\n",
      "o'clock         NOUN\n",
      "on              ADP\n",
      "Thursday        PROPN\n",
      "morning         NOUN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "This            DET\n",
      "is              VERB\n",
      "a               DET\n",
      "car             NOUN\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"This is a car\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      "!               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great...!\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ",               PUNCT\n",
      "was             VERB\n",
      "a               DET\n",
      "king            NOUN\n",
      "of              ADP\n",
      "the             DET\n",
      "ancient         ADJ\n",
      "Greek           ADJ\n",
      "kingdom         NOUN\n",
      "of              ADP\n",
      "Macedon         PROPN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great, was a king of the ancient Greek kingdom of Macedon.\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Stanford CoreNLP </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "2.2.1 Run Stanford CoreNLP in server mode\n",
    "\n",
    "2.2.2 Define a function\n",
    "\n",
    "2.2.3 Generate POS tags for given sentence\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Run Stanford CoreNLP in server mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the server using all jars in the current directory (e.g., the CoreNLP home directory)\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer --add-modules java.se.ee -port 9000 -timeout 15000\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stnfordpostagdemofunction(text):\n",
    "    output = nlp.annotate(text, properties={\n",
    "        'annotators': 'pos',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    for s in output[\"sentences\"]:\n",
    "        print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "        for t in s[\"tokens\"]:\n",
    "            print(u\"{:<16}{:>2}\".format(str(t[\"word\"]),str(t[\"pos\"])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Generate POS tags for given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "This            DT\n",
      "is              VBZ\n",
      "a               DT\n",
      "car             NN\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"This is a car.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       NNP\n",
      "the             DT\n",
      "Great           NNP\n",
      ",                ,\n",
      "was             VBD\n",
      "a               DT\n",
      "king            NN\n",
      "of              IN\n",
      "the             DT\n",
      "ancient         JJ\n",
      "Greek           JJ\n",
      "kingdom         NN\n",
      "of              IN\n",
      "Macedon         NNP\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"Alexander the Great, was a king of the ancient Greek kingdom of Macedon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "We              PRP\n",
      "will            MD\n",
      "meet            VB\n",
      "at              IN\n",
      "eight           CD\n",
      "o'clock         RB\n",
      "on              IN\n",
      "Thursday        NNP\n",
      "morning         NN\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"We will meet at eight o'clock on Thursday morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "The             DT\n",
      "name            NN\n",
      "of              IN\n",
      "your            PRP$\n",
      "medicine        NN\n",
      "is              VBZ\n",
      "Paracetamol     NNP\n",
      "500             CD\n",
      "mg              NN\n",
      "Tablets         NNS\n",
      "-LRB-           -LRB-\n",
      "called          VBN\n",
      "paracetamol     NNP\n",
      "throughout      IN\n",
      "this            DT\n",
      "leaflet         NN\n",
      "-RRB-           -RRB-\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"The name of your medicine is Paracetamol 500mg Tablets (called paracetamol throughout this leaflet).\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Spacy library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2.3.1 Import dependencies\n",
    "\n",
    "2.3.2 Load model\n",
    "\n",
    "2.3.3 Generate POS tag for given sentence\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Generate POS tag for given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                            Word Category                   POS Tag\n",
      "--------------------------------------------------------------------------------\n",
      "Apple                           PROPN                           NNP\n",
      "is                              VERB                            VBZ\n",
      "looking                         VERB                            VBG\n",
      "at                              ADP                             IN\n",
      "buying                          VERB                            VBG\n",
      "U.K.                            PROPN                           NNP\n",
      "startup                         NOUN                            NN\n",
      "for                             ADP                             IN\n",
      "$                               SYM                             $\n",
      "1                               NUM                             CD\n",
      "billion                         NUM                             CD\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print(\"{:<32}{:<32}{}\".format(\"Word\", \"Word Category\", \"POS Tag\")+\"\\n\"+\"-\"*80)\n",
    "for token in doc:\n",
    "    #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    print(u\"{:<32}{:<32}{}\".format(token.text,token.pos_, token.tag_))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Why do we need to develop our own POS tagger? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Dealing with domain specific terminology\n",
    "\n",
    "* Dealing with ambiguity \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                            Word Category                   POS Tag\n",
      "--------------------------------------------------------------------------------\n",
      "The                             DET                             DT\n",
      "name                            NOUN                            NN\n",
      "of                              ADP                             IN\n",
      "your                            ADJ                             PRP$\n",
      "medicine                        NOUN                            NN\n",
      "is                              VERB                            VBZ\n",
      "Paracetamol                     PROPN                           NNP\n",
      "500                             NUM                             CD\n",
      "mg                              ADJ                             JJ\n",
      "Tablets                         NOUN                            NNS\n",
      "(                               PUNCT                           -LRB-\n",
      "called                          VERB                            VBN\n",
      "paracetamol                     NOUN                            NN\n",
      "throughout                      ADP                             IN\n",
      "this                            DET                             DT\n",
      "leaflet                         NOUN                            NN\n",
      ")                               PUNCT                           -RRB-\n",
      ".                               PUNCT                           .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'The name of your medicine is Paracetamol 500mg Tablets (called paracetamol throughout this leaflet). ')\n",
    "print(\"{:<32}{:<32}{}\".format(\"Word\", \"Word Category\", \"POS Tag\")+\"\\n\"+\"-\"*80)\n",
    "for token in doc:\n",
    "    #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    print(u\"{:<32}{:<32}{}\".format(token.text,token.pos_, token.tag_)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
