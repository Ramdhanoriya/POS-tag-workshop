{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">  Generate Parts of Speech tags using various python libraries </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2.1 Generating POS tags using Polyglot library\n",
    "\n",
    "2.2 Generating POS tags using Stanford CoreNLP \n",
    "\n",
    "2.3 Generating POS tags using Spacy library\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Polyglot library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "2.1.1 Download polyglot POS model for English language\n",
    "\n",
    "2.1.2 Load POS model\n",
    "\n",
    "2.1.3 Import dependencies\n",
    "\n",
    "2.1.4 Detect the language\n",
    "\n",
    "2.1.5 Tokenization of the sentences\n",
    "\n",
    "2.1.6 Generate POS tags for given sentence\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Download polyglot POS model for English language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Slovene                    2. Danish                     3. Bulgarian                \n",
      "  4. Irish                      5. Czech                      6. Indonesian               \n",
      "  7. French                     8. Swedish                    9. Spanish; Castilian       \n",
      " 10. Finnish                   11. English                   12. German                   \n",
      " 13. Dutch                     14. Hungarian                 15. Portuguese               \n",
      " 16. Italian                  \n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(downloader.supported_languages_table(\"pos2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Load POS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/shetul/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /home/shetul/polyglot_data...\n",
      "[polyglot_data]   Package pos2.en is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.download(\"embeddings2.en\")\n",
    "downloader.download(\"pos2.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detected: Code=fr, Name=French\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Bonjour, Mesdames.\")\n",
    "print(\"Language Detected: Code={}, Name={}\\n\".format(text.language.code, text.language.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Tokenization of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.']\n"
     ]
    }
   ],
   "source": [
    "words_list = Text(\"Beautiful is better than ugly. \"\n",
    "           \"Explicit is better than implicit. \"\n",
    "           \"Simple is better than complex.\")\n",
    "print(words_list.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Generate POS tags for given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\"We will meet at eight o'clock on Thursday morning.\"\"\"\n",
    "text = Text(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRON'),\n",
       " ('will', 'AUX'),\n",
       " ('meet', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('eight', 'NUM'),\n",
       " (\"o'clock\", 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('Thursday', 'PROPN'),\n",
       " ('morning', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "We              PRON\n",
      "will            AUX\n",
      "meet            VERB\n",
      "at              ADP\n",
      "eight           NUM\n",
      "o'clock         NOUN\n",
      "on              ADP\n",
      "Thursday        PROPN\n",
      "morning         NOUN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "This            DET\n",
      "is              VERB\n",
      "a               DET\n",
      "car             NOUN\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"This is a car\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      "!               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great...!\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ",               PUNCT\n",
      "was             VERB\n",
      "a               DET\n",
      "king            NOUN\n",
      "of              ADP\n",
      "the             DET\n",
      "ancient         ADJ\n",
      "Greek           ADJ\n",
      "kingdom         NOUN\n",
      "of              ADP\n",
      "Macedon         PROPN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great, was a king of the ancient Greek kingdom of Macedon.\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Stanford CoreNLP </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "2.2.1 Run Stanford CoreNLP in server mode\n",
    "\n",
    "2.2.2 Define a function\n",
    "\n",
    "2.2.3 Generate POS tags for given sentence\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Run Stanford CoreNLP in server mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the server using all jars in the current directory (e.g., the CoreNLP home directory)\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer --add-modules java.se.ee -port 9000 -timeout 15000\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stnfordpostagdemofunction(text):\n",
    "    output = nlp.annotate(text, properties={\n",
    "        'annotators': 'pos',\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    for s in output[\"sentences\"]:\n",
    "        print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "        for t in s[\"tokens\"]:\n",
    "            print(u\"{:<16}{:>2}\".format(str(t[\"word\"]),str(t[\"pos\"])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Generate POS tags for given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "This            DT\n",
      "is              VBZ\n",
      "a               DT\n",
      "car             NN\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"This is a car.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       NNP\n",
      "the             DT\n",
      "Great           NNP\n",
      ",                ,\n",
      "was             VBD\n",
      "a               DT\n",
      "king            NN\n",
      "of              IN\n",
      "the             DT\n",
      "ancient         JJ\n",
      "Greek           JJ\n",
      "kingdom         NN\n",
      "of              IN\n",
      "Macedon         NNP\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"Alexander the Great, was a king of the ancient Greek kingdom of Macedon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "We              PRP\n",
      "will            MD\n",
      "meet            VB\n",
      "at              IN\n",
      "eight           CD\n",
      "o'clock         RB\n",
      "on              IN\n",
      "Thursday        NNP\n",
      "morning         NN\n",
      ".                .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stnfordpostagdemofunction(\"We will meet at eight o'clock on Thursday morning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Spacy library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2.3.1 Import dependencies\n",
    "\n",
    "2.3.2 Load model\n",
    "\n",
    "2.3.3 Generate POS tag for given sentence\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Generate POS tag for given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                            General POS Tags                POS Tag\n",
      "--------------------------------------------------------------------------------\n",
      "Apple                           PROPN                           NNP\n",
      "is                              VERB                            VBZ\n",
      "looking                         VERB                            VBG\n",
      "at                              ADP                             IN\n",
      "buying                          VERB                            VBG\n",
      "U.K.                            PROPN                           NNP\n",
      "startup                         NOUN                            NN\n",
      "for                             ADP                             IN\n",
      "$                               SYM                             $\n",
      "1                               NUM                             CD\n",
      "billion                         NUM                             CD\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print(\"{:<32}{:<32}{}\".format(\"Word\", \"General POS Tags\", \"POS Tag\")+\"\\n\"+\"-\"*80)\n",
    "for token in doc:\n",
    "    #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    print(u\"{:<32}{:<32}{}\".format(token.text,token.pos_, token.tag_))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
